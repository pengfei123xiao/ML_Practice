{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Keras_RNN_Classifier.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/prodigyxiao/ML_Practice/blob/master/Keras_RNN_Classifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "ko6uyoybzvE2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "f514517e-14ca-4366-a1cb-a68a4ac73d83"
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "np.random.seed(1000) # reproducibility\n",
        "from keras.models import Sequential\n",
        "from keras.layers import SimpleRNN, Activation, Dense\n",
        "from keras.optimizers import Adam\n",
        "from keras.utils import np_utils\n",
        "from keras.datasets import mnist # A built in dataset\n",
        "\n",
        "# 为了使用RNN，我们将图像理解为序列化数据,\n",
        "# 每一行作为一个输入单元，所以输入数据大小INPUT_SIZE = 28,\n",
        "# 先是第1行输入，再是第2行，第3行，第4行，…，第28行输入,\n",
        "# 一张图片就是一个序列，所以步长TIME_STEPS = 28。\n",
        "\n",
        "\n",
        "TIME_STEPS = 28 # 是要读取多少个时间点的数据，如果一次读一行需要读28次。\n",
        "INPUT_SIZE = 28 # 每次每一行读取多少个像素。\n",
        "BATCH_SIZE =50 # 每一批训练多少张。\n",
        "BATCH_INDEX =0 # 用来生成数据。\n",
        "OUTPUT_SIZE = 10 # 分类结果的长度，0到9，所以长度为 10。\n",
        "CELL_SIZE =50 # 网络中隐藏层要放多少个unit。\n",
        "LR =0.001 # Learning rate\n",
        "\n",
        "# Load data\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "\n",
        "# Normalization\n",
        "X_train = X_train.reshape(-1, 28, 28) / 255\n",
        "X_test = X_test.reshape(-1, 28, 28) / 255\n",
        "\n",
        "# One hot encoding\n",
        "y_train = np_utils.to_categorical(y_train, 10) \n",
        "y_test = np_utils.to_categorical(y_test, 10)\n",
        "\n",
        "# Build model\n",
        "model=Sequential()\n",
        "\n",
        "# RNN cell\n",
        "model.add(SimpleRNN(\n",
        "    # for batch_input_shape, if using tensorflow as the backend, we have to put None for the batch_size.\n",
        "    # Otherwise, model.evaluate() will get error.\n",
        "    batch_input_shape=(None, TIME_STEPS, INPUT_SIZE), # para:(BATCH_SIZE,TIME_STEPS, INPUT_SIZE) \n",
        "    output_dim=CELL_SIZE,\n",
        "    unroll=True,\n",
        "))\n",
        "\n",
        "# output layer\n",
        "model.add(Dense(OUTPUT_SIZE))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "# Compile model and declare loss function and optimizer\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "             optimizer='adam',\n",
        "             metrics=['accuracy'])\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:43: UserWarning: Update your `SimpleRNN` call to the Keras 2 API: `SimpleRNN(batch_input_shape=(None, 28,..., unroll=True, units=50)`\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "X6zJe93P67MA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        },
        "outputId": "88881503-1a54-4960-b70b-3f279e5a2cea"
      },
      "cell_type": "code",
      "source": [
        "# 每次训练的时候并不是取所有的数据，只是取BATCH_SIZE个序列，或者称为BATCH_SIZE张图片.\n",
        "# 这样可以大大降低运算时间，提高训练效率.\n",
        "# Train\n",
        "for step in range(5001):\n",
        "    # data shape = (batch_num, steps, inputs/outputs)\n",
        "    X_batch = X_train[BATCH_INDEX: BATCH_INDEX+BATCH_SIZE, :, :] # ***\n",
        "    Y_batch = y_train[BATCH_INDEX: BATCH_INDEX+BATCH_SIZE, :] # ***\n",
        "    cost = model.train_on_batch(X_batch, Y_batch)\n",
        "    BATCH_INDEX += BATCH_SIZE\n",
        "    BATCH_INDEX = 0 if BATCH_INDEX >= X_train.shape[0] else BATCH_INDEX\n",
        "\n",
        "    # Test\n",
        "    if step % 500 == 0:\n",
        "        cost, accuracy = model.evaluate(X_test, y_test, batch_size=y_test.shape[0], verbose=False)\n",
        "        print('step: ',step,'test cost: ', cost, 'test accuracy: ', accuracy)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "step:  0 test cost:  2.3441545963287354 test accuracy:  0.10369999706745148\n",
            "step:  500 test cost:  0.7419349551200867 test accuracy:  0.7533000111579895\n",
            "step:  1000 test cost:  0.4595576226711273 test accuracy:  0.8568999767303467\n",
            "step:  1500 test cost:  0.39361605048179626 test accuracy:  0.8808000087738037\n",
            "step:  2000 test cost:  0.3237840533256531 test accuracy:  0.906499981880188\n",
            "step:  2500 test cost:  0.2891175150871277 test accuracy:  0.9156000018119812\n",
            "step:  3000 test cost:  0.28184083104133606 test accuracy:  0.9207000136375427\n",
            "step:  3500 test cost:  0.2674790024757385 test accuracy:  0.9225999712944031\n",
            "step:  4000 test cost:  0.2517475485801697 test accuracy:  0.9300000071525574\n",
            "step:  4500 test cost:  0.24747426807880402 test accuracy:  0.9298999905586243\n",
            "step:  5000 test cost:  0.34998515248298645 test accuracy:  0.8898000121116638\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}